# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load the dataset
path = r"C:\Users\anany\Downloads\archive (9)\Cancer_Data.csv"
df = pd.read_csv(path)

# Preview data
print("First 5 rows:\n", df.head())
print("\nInfo:\n", df.info())

# Drop unnecessary columns like ID or unnamed
df = df.drop(columns=[col for col in df.columns if "Unnamed" in col or "id" in col.lower()])

# Encode target variable (if categorical)
if df['diagnosis'].dtype == 'object':
    le = LabelEncoder()
    df['diagnosis'] = le.fit_transform(df['diagnosis'])  # M=1, B=0

# Split features and labels
X = df.drop(columns=['diagnosis'])
y = df['diagnosis']

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Try different K values
accuracies = []
k_vals = range(1, 21)

for k in k_vals:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    preds = knn.predict(X_test)
    acc = accuracy_score(y_test, preds)
    accuracies.append(acc)

# Plot Accuracy vs K
plt.figure(figsize=(10, 5))
plt.plot(k_vals, accuracies, marker='o', linestyle='--', color='b')
plt.title("Accuracy vs K")
plt.xlabel("K Value")
plt.ylabel("Accuracy")
plt.grid(True)
plt.xticks(k_vals)
plt.show()

# Best K
best_k = k_vals[np.argmax(accuracies)]
print(f"‚úÖ Best K: {best_k}")

# Final model
final_knn = KNeighborsClassifier(n_neighbors=best_k)
final_knn.fit(X_train, y_train)
y_pred = final_knn.predict(X_test)

# Evaluation
print("\nüîç Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
